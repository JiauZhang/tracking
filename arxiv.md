<html>
        <body>
        <p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Contextual Conservative Q-Learning for Offline Reinforcement Learning<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01298<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Offline reinforcement learning learns an effective policy on offline datasets without online interaction, and it attracts persistent research attention due to its potential of practical application. However, extrapolation error generated by distribution shift will still lead to the overestimation for those actions that transit to out-of-distribution(OOD) states, which degrades the reliability and robustness of the offline policy. In this paper, we propose Contextual Conservative Q-Learning(C-CQL) to learn a robustly reliable policy through the contextual information captured via an inverse dynamics model. With the supervision of the inverse dynamics model, it tends to learn a policy that generates stable transition at perturbed states, for the fact that pertuebed states are a common kind of OOD states. In this manner, we enable the learnt policy more likely to generate transition that destines to the empirical next state distributions of the offline dataset, i.e., robustly reliable transition. Besides, we theoretically reveal that C-CQL is the generalization of the Conservative Q-Learning(CQL) and aggressive State Deviation Correction(SDC). Finally, experimental results demonstrate the proposed C-CQL achieves the state-of-the-art performance in most environments of offline Mujoco suite and a noisy Mujoco setting. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Diffusion approximations of Oja's online principal component analysis<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01339<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Oja's algorithm of principal component analysis (PCA) has been one of the methods utilized in practice to reduce dimension. In this paper, we focus on the convergence property of the discrete algorithm. To realize that, we view the algorithm as a stochastic process on the parameter space and semi-group. We approximate it by SDEs, and prove large time convergence of the SDEs to ensure its performance. This process is completed in three steps. First, the discrete algorithm can be viewed as a semigroup: $S^k\varphi=\mathbb{E}[\varphi(\mathbf W(k))]$. Second, we construct stochastic differential equations (SDEs) on the Stiefel manifold, i.e. the diffusion approximation, to approximate the semigroup. By proving the weak convergence, we verify that the algorithm is 'close to' the SDEs. Finally, we use the reversibility of the SDEs to prove long-time convergence. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Explainability and Robustness of Deep Visual Classification Models<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01343<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: In the computer vision community, Convolutional Neural Networks (CNNs), first proposed in the 1980's, have become the standard visual classification model. Recently, as alternatives to CNNs, Capsule Networks (CapsNets) and Vision Transformers (ViTs) have been proposed. CapsNets, which were inspired by the information processing of the human brain, are considered to have more inductive bias than CNNs, whereas ViTs are considered to have less inductive bias than CNNs. All three classification models have received great attention since they can serve as backbones for various downstream tasks. However, these models are far from being perfect. As pointed out by the community, there are two weaknesses in standard Deep Neural Networks (DNNs). One of the limitations of DNNs is the lack of explainability. Even though they can achieve or surpass human expert performance in the image classification task, the DNN-based decisions are difficult to understand. In many real-world applications, however, individual decisions need to be explained. The other limitation of DNNs is adversarial vulnerability. Concretely, the small and imperceptible perturbations of inputs can mislead DNNs. The vulnerability of deep neural networks poses challenges to current visual classification models. The potential threats thereof can lead to unacceptable consequences. Besides, studying model adversarial vulnerability can lead to a better understanding of the underlying models. Our research aims to address the two limitations of DNNs. Specifically, we focus on deep visual classification models, especially the core building parts of each classification model, e.g. dynamic routing in CapsNets and self-attention module in ViTs. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Neighbor Contrastive Learning on Learnable Graph Augmentation<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01404<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Recent years, graph contrastive learning (GCL), which aims to learn representations from unlabeled graphs, has made great progress. However, the existing GCL methods mostly adopt human-designed graph augmentations, which are sensitive to various graph datasets. In addition, the contrastive losses originally developed in computer vision have been directly applied to graph data, where the neighboring nodes are regarded as negatives and consequently pushed far apart from the anchor. However, this is contradictory with the homophily assumption of networks that connected nodes often belong to the same class and should be close to each other. In this work, we propose an end-to-end automatic GCL method, named NCLA to apply neighbor contrastive learning on learnable graph augmentation. Several graph augmented views with adaptive topology are automatically learned by the multi-head graph attention mechanism, which can be compatible with various graph datasets without prior domain knowledge. In addition, a neighbor contrastive loss is devised to allow multiple positives per anchor by taking network topology as the supervised signals. Both augmentations and embeddings are learned end-to-end in the proposed NCLA. Extensive experiments on the benchmark datasets demonstrate that NCLA yields the state-of-the-art node classification performance on self-supervised GCL and even exceeds the supervised ones, when the labels are extremely limited. Our code is released at https://github.com/shenxiaocam/NCLA. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Semi-MAE: Masked Autoencoders for Semi-supervised Vision Transformers<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01431<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Vision Transformer (ViT) suffers from data scarcity in semi-supervised learning (SSL). To alleviate this issue, inspired by masked autoencoder (MAE), which is a data-efficient self-supervised learner, we propose Semi-MAE, a pure ViT-based SSL framework consisting of a parallel MAE branch to assist the visual representation learning and make the pseudo labels more accurate. The MAE branch is designed as an asymmetric architecture consisting of a lightweight decoder and a shared-weights encoder. We feed the weakly-augmented unlabeled data with a high masking ratio to the MAE branch and reconstruct the missing pixels. Semi-MAE achieves 75.9% top-1 accuracy on ImageNet with 10% labels, surpassing prior state-of-the-art in semi-supervised image classification. In addition, extensive experiments demonstrate that Semi-MAE can be readily used for other ViT models and masked image modeling methods. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Accurate, Low-latency, Efficient SAR Automatic Target Recognition on  FPGA<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01454<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Synthetic aperture radar (SAR) automatic target recognition (ATR) is the key technique for remote-sensing image recognition. The state-of-the-art convolutional neural networks (CNNs) for SAR ATR suffer from \emph{high computation cost} and \emph{large memory footprint}, making them unsuitable to be deployed on resource-limited platforms, such as small/micro satellites. In this paper, we propose a comprehensive GNN-based model-architecture {co-design} on FPGA to address the above issues. \emph{Model design}: we design a novel graph neural network (GNN) for SAR ATR. The proposed GNN model incorporates GraphSAGE layer operators and attention mechanism, achieving comparable accuracy as the state-of-the-art work with near $1/100$ computation cost. Then, we propose a pruning approach including weight pruning and input pruning. While weight pruning through lasso regression reduces most parameters without accuracy drop, input pruning eliminates most input pixels with negligible accuracy drop. \emph{Architecture design}: to fully unleash the computation parallelism within the proposed model, we develop a novel unified hardware architecture that can execute various computation kernels (feature aggregation, feature transformation, graph pooling). The proposed hardware design adopts the Scatter-Gather paradigm to efficiently handle the irregular computation {patterns} of various computation kernels. We deploy the proposed design on an embedded FPGA (AMD Xilinx ZCU104) and evaluate the performance using MSTAR dataset. Compared with the state-of-the-art CNNs, the proposed GNN achieves comparable accuracy with $1/3258$ computation cost and $1/83$ model size. Compared with the state-of-the-art CPU/GPU, our FPGA accelerator achieves $14.8\times$/$2.5\times$ speedup (latency) and is $62\times$/$39\times$ more energy efficient. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Audio-Visual Efficient Conformer for Robust Speech Recognition<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01456<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: End-to-end Automatic Speech Recognition (ASR) systems based on neural networks have seen large improvements in recent years. The availability of large scale hand-labeled datasets and sufficient computing resources made it possible to train powerful deep neural networks, reaching very low Word Error Rate (WER) on academic benchmarks. However, despite impressive performance on clean audio samples, a drop of performance is often observed on noisy speech. In this work, we propose to improve the noise robustness of the recently proposed Efficient Conformer Connectionist Temporal Classification (CTC)-based architecture by processing both audio and visual modalities. We improve previous lip reading methods using an Efficient Conformer back-end on top of a ResNet-18 visual front-end and by adding intermediate CTC losses between blocks. We condition intermediate block features on early predictions using Inter CTC residual modules to relax the conditional independence assumption of CTC-based models. We also replace the Efficient Conformer grouped attention by a more efficient and simpler attention mechanism that we call patch attention. We experiment with publicly available Lip Reading Sentences 2 (LRS2) and Lip Reading Sentences 3 (LRS3) datasets. Our experiments show that using audio and visual modalities allows to better recognize speech in the presence of environmental noise and significantly accelerate training, reaching lower WER with 4 times less training steps. Our Audio-Visual Efficient Conformer (AVEC) model achieves state-of-the-art performance, reaching WER of 2.3% and 1.8% on LRS2 and LRS3 test sets. Code and pretrained models are available at https://github.com/burchim/AVEC. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: On Fairness of Medical Image Classification with Multiple Sensitive  Attributes via Learning Orthogonal Representations<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01481<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Mitigating the discrimination of machine learning models has gained increasing attention in medical image analysis. However, rare works focus on fair treatments for patients with multiple sensitive demographic ones, which is a crucial yet challenging problem for real-world clinical applications. In this paper, we propose a novel method for fair representation learning with respect to multi-sensitive attributes. We pursue the independence between target and multi-sensitive representations by achieving orthogonality in the representation space. Concretely, we enforce the column space orthogonality by keeping target information on the complement of a low-rank sensitive space. Furthermore, in the row space, we encourage feature dimensions between target and sensitive representations to be orthogonal. The effectiveness of the proposed method is demonstrated with extensive experiments on the CheXpert dataset. To our best knowledge, this is the first work to mitigate unfairness with respect to multiple sensitive attributes in the field of medical imaging. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Towards a Pipeline for Real-Time Visualization of Faces for VR-based  Telepresence and Live Broadcasting Utilizing Neural Rendering<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01490<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: While head-mounted displays (HMDs) for Virtual Reality (VR) have become widely available in the consumer market, they pose a considerable obstacle for a realistic face-to-face conversation in VR since HMDs hide a significant portion of the participants faces. Even with image streams from cameras directly attached to an HMD, stitching together a convincing image of an entire face remains a challenging task because of extreme capture angles and strong lens distortions due to a wide field of view. Compared to the long line of research in VR, reconstruction of faces hidden beneath an HMD is a very recent topic of research. While the current state-of-the-art solutions demonstrate photo-realistic 3D reconstruction results, they require high-cost laboratory equipment and large computational costs. We present an approach that focuses on low-cost hardware and can be used on a commodity gaming computer with a single GPU. We leverage the benefits of an end-to-end pipeline by means of Generative Adversarial Networks (GAN). Our GAN produces a frontal-facing 2.5D point cloud based on a training dataset captured with an RGBD camera. In our approach, the training process is offline, while the reconstruction runs in real-time. Our results show adequate reconstruction quality within the 'learned' expressions. Expressions not learned by the network produce artifacts and can trigger the Uncanny Valley effect. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Robofriend: An Adpative Storytelling Robotic Teddy Bear - Technical  Report<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01576<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: In this paper we describe Robofriend, a robotic teddy bear for telling stories to young children. Robofriend adapts its behavior to keep the childrens' attention using reinforcement learning. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Hospital transfer risk prediction for COVID-19 patients from a  medicalized hotel based on Diffusion GraphSAGE<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01596<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: The global COVID-19 pandemic has caused more than six million deaths worldwide. Medicalized hotels were established in Taiwan as quarantine facilities for COVID-19 patients with no or mild symptoms. Due to limited medical care available at these hotels, it is of paramount importance to identify patients at risk of clinical deterioration. This study aimed to develop and evaluate a graph-based deep learning approach for progressive hospital transfer risk prediction in a medicalized hotel setting. Vital sign measurements were obtained for 632 patients and daily patient similarity graphs were constructed. Inductive graph convolutional network models were trained on top of the temporally integrated graphs to predict hospital transfer risk. The proposed models achieved AUC scores above 0.83 for hospital transfer risk prediction based on the measurements of past 1, 2, and 3 days, outperforming baseline machine learning methods. A post-hoc analysis on the constructed diffusion-based graph using Local Clustering Coefficient discovered a high-risk cluster with significantly older mean age, higher body temperature, lower SpO2, and shorter length of stay. Further time-to-hospital-transfer survival analysis also revealed a significant decrease in survival probability in the discovered high-risk cluster. The obtained results demonstrated promising predictability and interpretability of the proposed graph-based approach. This technique may help preemptively detect high-risk patients at community-based medical facilities similar to a medicalized hotel. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: SPTS v2: Single-Point Scene Text Spotting<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01635<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: End-to-end scene text spotting has made significant progress due to its intrinsic synergy between text detection and recognition. Previous methods commonly regard manual annotations such as horizontal rectangles, rotated rectangles, quadrangles,and polygons as a prerequisite, which are much more expensive than using single-point. For the first time, we demonstrate that training scene text spotting models can be achieved with an extremely low-cost single-point annotation by the proposed framework, termed SPTS v2. SPTS v2 reserves the advantage of the auto-regressive Transformer with an Instance Assignment Decoder (IAD) through sequentially predicting the center points of all text instances inside the same predicting sequence, while with a Parallel Recognition Decoder (PRD) for text recognition in parallel. These two decoders share the same parameters and are interactively connected with a simple but effective information transmission process to pass the gradient and information. Comprehensive experiments on various existing benchmark datasets demonstrate the SPTS v2 can outperform previous state-of-the-art single-point text spotters with fewer parameters while achieving 14x faster inference speed. Most importantly, within the scope of our SPTS v2, extensive experiments further reveal an important phenomenon that single-point serves as the optimal setting for the scene text spotting compared to non-point, rectangular bounding box, and polygonal bounding box. Such an attempt provides a significant opportunity for scene text spotting applications beyond the realms of existing paradigms. Code is available at https://github.com/shannanyinxiang/SPTS. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Cryptographic Group and Semigroup Actions<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01657<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: We consider actions of a group or a semigroup on a set, which generalize the setup of discrete logarithm based cryptosystems. Such cryptographic group actions have gained increasing attention recently in the context of isogeny-based cryptography. We introduce generic algorithms for the semigroup action problem and discuss lower and upper bounds. Also, we investigate Pohlig-Hellman type attacks in a general sense. In particular, we consider reductions provided by non-invertible elements in a semigroup, and we deal with subgroups in the case of group actions. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Multi-Aspect Explainable Inductive Relation Prediction by Sentence  Transformer<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01664<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Recent studies on knowledge graphs (KGs) show that path-based methods empowered by pre-trained language models perform well in the provision of inductive and explainable relation predictions. In this paper, we introduce the concepts of relation path coverage and relation path confidence to filter out unreliable paths prior to model training to elevate the model performance. Moreover, we propose Knowledge Reasoning Sentence Transformer (KRST) to predict inductive relations in KGs. KRST is designed to encode the extracted reliable paths in KGs, allowing us to properly cluster paths and provide multi-aspect explanations. We conduct extensive experiments on three real-world datasets. The experimental results show that compared to SOTA models, KRST achieves the best performance in most transductive and inductive test cases (4 of 6), and in 11 of 12 few-shot test cases. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: GUAP: Graph Universal Attack Through Adversarial Patching<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01731<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Graph neural networks (GNNs) are a class of effective deep learning models for node classification tasks; yet their predictive capability may be severely compromised under adversarially designed unnoticeable perturbations to the graph structure and/or node data. Most of the current work on graph adversarial attacks aims at lowering the overall prediction accuracy, but we argue that the resulting abnormal model performance may catch attention easily and invite quick counterattack. Moreover, attacks through modification of existing graph data may be hard to conduct if good security protocols are implemented. In this work, we consider an easier attack harder to be noticed, through adversarially patching the graph with new nodes and edges. The attack is universal: it targets a single node each time and flips its connection to the same set of patch nodes. The attack is unnoticeable: it does not modify the predictions of nodes other than the target. We develop an algorithm, named GUAP, that achieves high attack success rate but meanwhile preserves the prediction accuracy. GUAP is fast to train by employing a sampling strategy. We demonstrate that a 5% sampling in each epoch yields 20x speedup in training, with only a slight degradation in attack performance. Additionally, we show that the adversarial patch trained with the graph convolutional network transfers well to other GNNs, such as the graph attention network. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Chatbots as Problem Solvers: Playing Twenty Questions with Role  Reversals<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01743<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: New chat AI applications like ChatGPT offer an advanced understanding of question context and memory across multi-step tasks, such that experiments can test its deductive reasoning. This paper proposes a multi-role and multi-step challenge, where ChatGPT plays the classic twenty-questions game but innovatively switches roles from the questioner to the answerer. The main empirical result establishes that this generation of chat applications can guess random object names in fewer than twenty questions (average, 12) and correctly guess 94% of the time across sixteen different experimental setups. The research introduces four novel cases where the chatbot fields the questions, asks the questions, both question-answer roles, and finally tries to guess appropriate contextual emotions. One task that humans typically fail but trained chat applications complete involves playing bilingual games of twenty questions (English answers to Spanish questions). Future variations address direct problem-solving using a similar inquisitive format to arrive at novel outcomes deductively, such as patentable inventions or combination thinking. Featured applications of this dialogue format include complex protein designs, neuroscience metadata, and child development educational materials. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Neural SDEs for Conditional Time Series Generation and the  Signature-Wasserstein-1 metric<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01315<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: (Conditional) Generative Adversarial Networks (GANs) have found great success in recent years, due to their ability to approximate (conditional) distributions over extremely high dimensional spaces. However, they are highly unstable and computationally expensive to train, especially in the time series setting. Recently, it has been proposed the use of a key object in rough path theory, called the signature of a path, which is able to convert the min-max formulation given by the (conditional) GAN framework into a classical minimization problem. However, this method is extremely expensive in terms of memory cost, sometimes even becoming prohibitive. To overcome this, we propose the use of \textit{Conditional Neural Stochastic Differential Equations}, which have a constant memory cost as a function of depth, being more memory efficient than traditional deep learning architectures. We empirically test that this proposed model is more efficient than other classical approaches, both in terms of memory cost and computational time, and that it usually outperforms them in terms of performance. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: Modeling the Rhythm from Lyrics for Melody Generation of Pop Song<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01361<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Creating a pop song melody according to pre-written lyrics is a typical practice for composers. A computational model of how lyrics are set as melodies is important for automatic composition systems, but an end-to-end lyric-to-melody model would require enormous amounts of paired training data. To mitigate the data constraints, we adopt a two-stage approach, dividing the task into lyric-to-rhythm and rhythm-to-melody modules. However, the lyric-to-rhythm task is still challenging due to its multimodality. In this paper, we propose a novel lyric-to-rhythm framework that includes part-of-speech tags to achieve better text setting, and a Transformer architecture designed to model long-term syllable-to-note associations. For the rhythm-to-melody task, we adapt a proven chord-conditioned melody Transformer, which has achieved state-of-the-art results. Experiments for Chinese lyric-to-melody generation show that the proposed framework is able to model key characteristics of rhythm and pitch distributions in the dataset, and in a subjective evaluation, the melodies generated by our system were rated as similar to or better than those of a state-of-the-art alternative. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/><p style="color: black; font-size: 14px; text-align: left; visibility: visible;"><b style="visibility: visible;">Title</b>: A deep local attention network for pre-operative lymph node metastasis  prediction in pancreatic cancer via multiphase CT imaging<br style="visibility: visible;"/><b style="visibility: visible;">PDF</b>: https://arxiv.org/pdf/2301.01448<br style="visibility: visible;"/></p><section style="margin-right: auto; margin-left: auto; padding: 0.2em; max-width: 100%; box-sizing: border-box; height: 12em; color: rgb(102, 101, 101); font-size: 14px; line-height: 1.3em; overflow: auto; overflow-wrap: break-word !important; background: rgb(240, 240, 240); text-align: left; visibility: visible;">
        <span style="font-size: 12px; visibility: visible;">
        <b style="visibility: visible;">Abstract</b>: Lymph node (LN) metastasis status is one of the most critical prognostic and cancer staging factors for patients with resectable pancreatic ductal adenocarcinoma (PDAC), or in general, for any types of solid malignant tumors. Preoperative prediction of LN metastasis from non-invasive CT imaging is highly desired, as it might be straightforwardly used to guide the following neoadjuvant treatment decision and surgical planning. Most studies only capture the tumor characteristics in CT imaging to implicitly infer LN metastasis and very few work exploit direct LN's CT imaging information. To the best of our knowledge, this is the first work to propose a fully-automated LN segmentation and identification network to directly facilitate the LN metastasis status prediction task. Nevertheless LN segmentation/detection is very challenging since LN can be easily confused with other hard negative anatomic structures (e.g., vessels) from radiological images. We explore the anatomical spatial context priors of pancreatic LN locations by generating a guiding attention map from related organs and vessels to assist segmentation and infer LN status. As such, LN segmentation is impelled to focus on regions that are anatomically adjacent or plausible with respect to the specific organs and vessels. The metastasized LN identification network is trained to classify the segmented LN instances into positives or negatives by reusing the segmentation network as a pre-trained backbone and padding a new classification head. More importantly, we develop a LN metastasis status prediction network that combines the patient-wise aggregation results of LN segmentation/identification and deep imaging features extracted from the tumor region. Extensive quantitative nested five-fold cross-validation is conducted on a discovery dataset of 749 patients with PDAC. <br style="visibility: visible;"/></span>
        </section><br style="visibility: visible;"/></body>
        </html>
